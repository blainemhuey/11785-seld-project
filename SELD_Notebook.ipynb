{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torchaudio\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "0od7MgU6ngPU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T4CGAo7g5zH",
        "outputId": "77e1eefe-96a9-4ac7-cc47-fc0b655bae64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://zenodo.org/record/6387880/files/foa_dev.zip?download=1 --output /content/gdrive/MyDrive/ProjectData/foa_dev.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPEnORZ6hAxm",
        "outputId": "d2670467-dec5-438b-948d-f4fc22d4f3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2097M  100 2097M    0     0  20.8M      0  0:01:40  0:01:40 --:--:-- 27.9M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://zenodo.org/record/6387880/files/metadata_dev.zip?download=1 --output /content/gdrive/MyDrive/ProjectData/metadata_dev.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdCVsOzSjcL_",
        "outputId": "e29f1daf-b4b4-46c4-8664-9c06975eac64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  619k  100  619k    0     0   334k      0  0:00:01  0:00:01 --:--:--  334k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/gdrive/MyDrive/ProjectData/foa_dev.zip -d /content/gdrive/MyDrive/ProjectData/data"
      ],
      "metadata": {
        "id": "SGtOHzsplak8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/gdrive/MyDrive/ProjectData/metadata_dev.zip -d /content/gdrive/MyDrive/ProjectData/data\n"
      ],
      "metadata": {
        "id": "kv2_F49SlvpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "SOUND_EVENT_CLASSES = [\n",
        "    \"Female speech, woman speaking\",\n",
        "    \"Male speech, man speaking\",\n",
        "    \"Clapping\",\n",
        "    \"Telephone\",\n",
        "    \"Laughter\",\n",
        "    \"Domestic sounds\",\n",
        "    \"Walk, footsteps\",\n",
        "    \"Door, open or close\",\n",
        "    \"Music\",\n",
        "    \"Musical instrument\",\n",
        "    \"Water tap, faucet\",\n",
        "    \"Bell\",\n",
        "    \"Knock\"\n",
        "]"
      ],
      "metadata": {
        "id": "o64yGQJ36pra"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \n",
        "    \"track\" : 3,\n",
        "    \"classes\" : len(SOUND_EVENT_CLASSES),\n",
        "    \n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "aB4UQ0nm6iRm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89AXijawcFsW",
        "outputId": "c2265176-2985-4f58-d235-b45abe2502a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classes': 13, 'track': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.nn.functional import pad\n",
        "\n",
        "SOUND_EVENT_CLASSES = [\n",
        "    \"Female speech, woman speaking\",\n",
        "    \"Male speech, man speaking\",\n",
        "    \"Clapping\",\n",
        "    \"Telephone\",\n",
        "    \"Laughter\",\n",
        "    \"Domestic sounds\",\n",
        "    \"Walk, footsteps\",\n",
        "    \"Door, open or close\",\n",
        "    \"Music\",\n",
        "    \"Musical instrument\",\n",
        "    \"Water tap, faucet\",\n",
        "    \"Bell\",\n",
        "    \"Knock\"\n",
        "]\n",
        "\n",
        "\n",
        "class FOADataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom PyTorch Dataset for DCASE FOA Datsets\n",
        "    \"\"\"\n",
        "\n",
        "    implemented_model_features = [\"seldnet\", \"rd3net\"]\n",
        "\n",
        "    def __init__(self, data_path, folds=None, train=True, model=\"seldnet\", hop_length=20, context=0, subset=False):\n",
        "        \"\"\"\n",
        "        Init Function for FOADataset\n",
        "        :param data_path: String path to root folder containing 'foa_dev' and 'metadata_dev'\n",
        "        :param folds: List of fold integers to use in this dataset\n",
        "        :param train: Bool indicating whether to use train dataset of val dataset\n",
        "        \"\"\"\n",
        "\n",
        "        # Assert that requested features are currently implemented\n",
        "        assert model in FOADataset.implemented_model_features\n",
        "        feat_size = 250\n",
        "        hop_length = 20\n",
        "        self.model = model\n",
        "        self.subset = subset\n",
        "        # Calculate Directory Names\n",
        "        foa_directory_sony = osp.join(data_path, \"foa_dev\", \"dev-train-sony\" if train else \"dev-test-sony\")\n",
        "        meta_directory_sony = osp.join(data_path, \"metadata_dev\", \"dev-train-sony\" if train else \"dev-test-sony\")\n",
        "        foa_directory_tau = osp.join(data_path, \"foa_dev\", \"dev-train-tau\" if train else \"dev-test-tau\")\n",
        "        meta_directory_tau = osp.join(data_path, \"metadata_dev\", \"dev-train-tau\" if train else \"dev-test-tau\")\n",
        "\n",
        "        all_foa_files = [osp.join(foa_directory_tau, file) for file in os.listdir(foa_directory_tau)]\n",
        "        all_foa_files.extend([osp.join(foa_directory_sony, file) for file in os.listdir(foa_directory_sony)])\n",
        "        all_meta_files = [osp.join(meta_directory_tau, file) for file in os.listdir(meta_directory_tau)]\n",
        "        all_meta_files.extend([osp.join(meta_directory_sony, file) for file in os.listdir(meta_directory_sony)])\n",
        "\n",
        "        # Parse File Names\n",
        "        foa_file_data = [self.parse_foa_file_name(file) for file in all_foa_files]\n",
        "        meta_file_data = [self.parse_foa_file_name(file) for file in all_meta_files]\n",
        "\n",
        "        # Create Lists of All Valid File Paths in Given Folds\n",
        "        self.folds = folds\n",
        "        self.foa_files = [\n",
        "            file for file, data in zip(all_foa_files, foa_file_data)\n",
        "            if (folds is None or data[\"fold\"] in folds)\n",
        "        ]\n",
        "        self.foa_files.sort()\n",
        "        self.meta_files = [\n",
        "            file for file, data in zip(all_meta_files, meta_file_data)\n",
        "            if (folds is None or data[\"fold\"] in folds)\n",
        "        ]\n",
        "        self.meta_files.sort()\n",
        "        if self.subset:\n",
        "          self.foa_files = self.foa_files[:30]\n",
        "          self.meta_files = self.meta_files[:30]\n",
        "\n",
        "        assert len(self.foa_files) == len(self.meta_files)\n",
        "\n",
        "        # Load SELDNet Input Features and ACCDOA Output\n",
        "        features = []\n",
        "        multi_accdoas = []\n",
        "        self.feature_width = 100 // hop_length\n",
        "        for foa_file, meta_file in zip(self.foa_files, self.meta_files):\n",
        "            if model == \"seldnet\":\n",
        "                feature = self.audio_to_seldnet_features(foa_file, hop_length=hop_length)[:,:, :-1]\n",
        "                multi_accdoa = self.metadata_to_multi_accdoa(self.load_metadata(meta_file),\n",
        "                                                         total_frames=feature.shape[2] // (100 // 20))\n",
        "                # print(multi_accdoa.shape)\n",
        "                feature_chunked = self.chunk_seldnet_feature(feature, feat_size)\n",
        "                multi_accdoa_chunked = self.chunk_seldnet_multiaccdoa(multi_accdoa, feat_size, hop_length )\n",
        "                # print(len(feature_chunked))\n",
        "                # print(len(multi_accdoa_chunked))\n",
        "                # print(feature.shape)\n",
        "                # print(multi_accdoa.shape)\n",
        "\n",
        "                assert(len(feature_chunked) == len(multi_accdoa_chunked))\n",
        "                features.extend(feature_chunked)\n",
        "                multi_accdoas.extend(multi_accdoa_chunked)\n",
        "\n",
        "            else:\n",
        "                feature = self.audio_to_rd3net_features(foa_file, hop_length=hop_length)\n",
        "                total_frames = feature.shape[2] // (100 // hop_length)\n",
        "                feature = feature[:, :, :total_frames * (100 // hop_length)]\n",
        "                multi_accdoa = self.metadata_to_multi_accdoa(self.load_metadata(meta_file),\n",
        "                                                             total_frames=total_frames)\n",
        "                features.append(feature)\n",
        "                multi_accdoas.append(multi_accdoa)\n",
        "\n",
        "        if model==\"seldnet\":\n",
        "            self.features = np.stack(features)\n",
        "            self.multi_accdoa = np.stack(multi_accdoas)\n",
        "        else:\n",
        "            self.features = pad(torch.concat(features, dim=-1), (context, context))\n",
        "            self.multi_accdoa = np.concatenate(multi_accdoas, axis=-1)\n",
        "        self.context = context\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_foa_file_name(file):\n",
        "        \"\"\"\n",
        "        Parses filenames of the following format:\n",
        "        \"fold[fold number]_room[room number per fold]_mix[recording number per room per split].wav\"\n",
        "        :param file: filename\n",
        "        :return: metadata dictionary\n",
        "        \"\"\"\n",
        "\n",
        "        name, extension = osp.splitext(osp.basename(file))\n",
        "        fold_text, room_text, mix_text = name.split(\"_\")\n",
        "        fold = int(fold_text.replace(\"fold\", \"\"))\n",
        "        room = int(room_text.replace(\"room\", \"\"))\n",
        "        mix = int(mix_text.replace(\"mix\", \"\"))\n",
        "        return {\"fold\": fold, \"room\": room, \"mix\": mix}\n",
        "\n",
        "    @staticmethod\n",
        "    def audio_to_seldnet_features(file, fft_size=1024, hop_length=20, eps=1e-8):\n",
        "        \"\"\"\n",
        "        Generates the SELDNet Input Features\n",
        "        :param file: Filepath to Audio File to Load\n",
        "        :param fft_size: Size of FFT calculation to perform\n",
        "        :param hop_length: Stride of FFT in ms\n",
        "        :param eps: Division eps to prevent NaN outputs\n",
        "        :return: torch.Tensor of Shape 7x64xT\n",
        "        \"\"\"\n",
        "        waveform, sample_rate = torchaudio.load(file, normalize=True)\n",
        "\n",
        "        spec_trans = torchaudio.transforms.Spectrogram(n_fft=fft_size, hop_length=sample_rate // (1000 // hop_length),\n",
        "                                                       pad=0, power=None)\n",
        "        mel_trans = torchaudio.transforms.MelScale(n_mels=64, sample_rate=sample_rate, n_stft=fft_size // 2 + 1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            spectrogram = spec_trans(waveform)\n",
        "            mel_spec = mel_trans(torch.real(torch.pow(spectrogram, 2)))\n",
        "\n",
        "            intensity = torch.real(torch.conj(spectrogram[0]) * spectrogram[1:])\n",
        "            intensity = intensity / (torch.pow(torch.abs(spectrogram[0]), 2) +\n",
        "                                     torch.mean(torch.pow(torch.abs(spectrogram[1:]), 2), dim=0) + eps)\n",
        "            mel_intensity = mel_trans(intensity)\n",
        "        return torch.concat((mel_spec, mel_intensity), dim=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def audio_to_rd3net_features(file, fft_size=1024, hop_length=20):\n",
        "        \"\"\"\n",
        "        Generates the RD3Net Input Features\n",
        "        :param file: Filepath to Audio File to Load\n",
        "        :param fft_size: Size of FFT calculation to perform\n",
        "        :param hop_length: Stride of FFT in ms\n",
        "        :return: torch.Tensor of Shape 7x(fft/2+1)xT\n",
        "        \"\"\"\n",
        "        waveform, sample_rate = torchaudio.load(file, normalize=True)\n",
        "\n",
        "        spec_trans = torchaudio.transforms.Spectrogram(n_fft=fft_size, hop_length=sample_rate // (1000 // hop_length),\n",
        "                                                       pad=0, power=None)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            spectrogram = spec_trans(waveform)\n",
        "\n",
        "            amplitude = torch.abs(spectrogram)\n",
        "            ipd = torch.angle(spectrogram[0]) - torch.angle(spectrogram[1:])\n",
        "\n",
        "        return torch.concat((amplitude, ipd), dim=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_metadata(file):\n",
        "        \"\"\"\n",
        "        Reads in the CSV Label File of the Format\n",
        "        '[frame number (int)], [active class index (int)], [source number index (int)], [azimuth (int)], [elevation (int)]'\n",
        "\n",
        "        :param file: Filepath to CSV File to Load\n",
        "        :return: List of Metadata Dictionaries\n",
        "        \"\"\"\n",
        "        metadata = []\n",
        "        with open(file, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                frame_number, active_class, source_number, azimuth, elevation = line.split(\",\")\n",
        "                metadata.append({\n",
        "                    \"frame_number\": int(frame_number),\n",
        "                    \"active_class\": int(active_class),\n",
        "                    \"source_number\": int(source_number),\n",
        "                    \"azimuth\": int(azimuth),\n",
        "                    \"elevation\": int(elevation)\n",
        "                })\n",
        "        return metadata\n",
        "\n",
        "    @staticmethod\n",
        "    def metadata_to_multi_accdoa(metadata, total_frames, n=3, c=len(SOUND_EVENT_CLASSES)):\n",
        "        \"\"\"\n",
        "        Turns a List of Python Dictionaries with SELD Labels Into A Multi-ACCDOA Truth Vector\n",
        "        :param metadata: List of Python Dictionaries (from 'load_metadata')\n",
        "        :param total_frames: Total number of 100ms frames in source audio\n",
        "        :param n: Maximum number of repetitions\n",
        "        :param c: Number of classes\n",
        "        :return: N x 3 x C x Total Frames Numpy Ndarray\n",
        "        \"\"\"\n",
        "        multi_accdoa = np.zeros((n, 3, c, total_frames))\n",
        "        event_count_per_frame = np.zeros((c, total_frames), dtype=np.int)\n",
        "        for metadata_i in metadata:\n",
        "            f, a, s, az, el = (metadata_i[\"frame_number\"], metadata_i[\"active_class\"], metadata_i[\"source_number\"],\n",
        "                               metadata_i[\"azimuth\"], metadata_i[\"elevation\"])\n",
        "            f -= 1\n",
        "            norm_az_el = np.array([np.cos(np.deg2rad(az)), np.sin(np.deg2rad(az)), np.sin(np.deg2rad(el))])\n",
        "            multi_accdoa[event_count_per_frame[a, f]:, :, a, f] = norm_az_el\n",
        "            event_count_per_frame[a, f] += 1\n",
        "        return multi_accdoa\n",
        "\n",
        "    @staticmethod\n",
        "    def chunk_seldnet_feature(feature, feat_size=250):\n",
        "      \n",
        "      s0,s1,s2 = feature.shape\n",
        "      # print(feature.shape)\n",
        "      news2 = int(np.ceil(s2/feat_size)*feat_size)\n",
        "      # print(\"padded length  \", news2)\n",
        "      feature = np.pad(feature, ((0,0), (0,0), (0,news2-s2)))\n",
        "      # print(feature.shape, \"  new feature shape\")\n",
        "      feature = np.reshape(feature, (7,news2,64))\n",
        "      return np.split(feature, news2/feat_size, axis=1 )\n",
        "      # return feature\n",
        "\n",
        "    @staticmethod\n",
        "    def chunk_seldnet_multiaccdoa(multi_accdoa,feat_size, hop_length):\n",
        "      split_size = feat_size//(100//hop_length)\n",
        "      # print(multi_accdoa.shape, \"  multi accdoa shape\")\n",
        "      # print(split_size, \" split size\")\n",
        "      split_count = multi_accdoa.shape[-1]/split_size\n",
        "      toPad = int(np.ceil(split_count)*split_size) - multi_accdoa.shape[-1]\n",
        "\n",
        "      multi_accdoa = np.pad(multi_accdoa, ((0,0), (0,0),(0,0), (0,toPad)))\n",
        "      # print(multi_accdoa.shape, \"  multi accdoa shape\")\n",
        "      split_count = multi_accdoa.shape[-1]/split_size\n",
        "      # print(split_count)\n",
        "\n",
        "\n",
        "      return np.split(multi_accdoa, split_count, axis=-1)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.model==\"seldnet\":\n",
        "            return self.features.shape[0]\n",
        "        return self.multi_accdoa.shape[-1]\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        if self.model ==\"seldnet\":\n",
        "            return torch.from_numpy(self.features[item]), torch.from_numpy(self.multi_accdoa[item])\n",
        "        return self.features[:, :, item*self.feature_width:(item+1)*self.feature_width+self.context*2], \\\n",
        "               self.multi_accdoa[:, :, :, item]\n"
      ],
      "metadata": {
        "id": "-704lZgYmJQr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oH7XUvTtYvXk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = FOADataset(\"/content/gdrive/MyDrive/ProjectData/data\", subset=True)\n",
        "train_loader = torch.utils.data.DataLoader( train_data , batch_size= 128, shuffle=True, drop_last=True)\n",
        "\n",
        "\n",
        "print(len(train_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Di4BasfnK0x",
        "outputId": "30c21fd8-6743-404c-e47f-33abe02cdc60"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:216: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dap44TGuqosJ",
        "outputId": "a000cd88-ee26-4aa1-fabc-420b1cf0ebda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(190, 7, 250, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To import files, on colab I am keeping them in the ProjectData folder might not be needed locally"
      ],
      "metadata": {
        "id": "q_PIrhyEvnZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys  \n",
        "# sys.path.insert(0, '/content/gdrive/MyDrive/ProjectData')"
      ],
      "metadata": {
        "id": "7eRzCuQynunX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from foa_dataset import FOADataset as FOADataset2"
      ],
      "metadata": {
        "id": "8qiZOA1OvAt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data2 = FOADataset2(\"/content/gdrive/MyDrive/ProjectData/data\")\n",
        "# train_loader = torch.utils.data.DataLoader( train_data , batch_size= 2, shuffle=True)\n",
        "\n",
        "\n",
        "# print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "XGX-38qXvzEK",
        "outputId": "a5806c7b-ff1b-4ed2-d3c9-edab8f4e444d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9abee3bd4de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFOADataset2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/ProjectData/data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/ProjectData/foa_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path, folds, train)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_to_foa_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoa_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             multi_accdoa = self.metadata_to_multi_accdoa(self.load_metadata(meta_file),\n\u001b[0;32m---> 77\u001b[0;31m                                                          total_frames=feature.shape[2])\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mmulti_accdoas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_accdoa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/ProjectData/foa_dataset.py\u001b[0m in \u001b[0;36mmetadata_to_multi_accdoa\u001b[0;34m(metadata, total_frames, n, c)\u001b[0m\n\u001b[1;32m    151\u001b[0m                                metadata_i[\"azimuth\"], metadata_i[\"elevation\"])\n\u001b[1;32m    152\u001b[0m             \u001b[0mnorm_az_el\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeg2rad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeg2rad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeg2rad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mmulti_accdoa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent_count_per_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_az_el\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mevent_count_per_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmulti_accdoa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3,1) into shape (2,3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import tor\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "\n",
        "\tdef __init__(self, max_pool = (5,4), out_filter=64, in_filter=64, kernel_size=3, dropout_rate=0.01):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.max_pool = max_pool\n",
        "\t\tself.out_filter = out_filter\n",
        "\t\tself.conv = nn.Conv2d(in_filter,out_filter, kernel_size=kernel_size, padding=(1,1))\n",
        "\t\tself.bn = nn.BatchNorm2d(out_filter)\n",
        "\t\tself.mpool = nn.MaxPool2d(self.max_pool)\n",
        "\t\tself.dropout = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "\tdef forward(self,x):\n",
        "\t\tx = self.conv(x)\n",
        "\t\tx = self.bn(x)\n",
        "\t\tx = nn.ReLU()(x)\n",
        "\t\tx = self.mpool(x)\n",
        "\t\tx = self.dropout(x)\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "\n",
        "class Network_Seldnet(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\t# print(\"Here\")\n",
        "\t\tmax_pool_list = [(5,4),(1,4),(1,2)]\n",
        "\t\tself.conv_list = nn.ModuleList()\n",
        "\t\tfor i,pool in enumerate(max_pool_list):\n",
        "\t\t\t# print(\"adding pool \")\n",
        "\t\t\tif i == 0:\n",
        "\t\t\t\tself.conv_list.append(\n",
        "\t\t\t\t\tConvBlock(pool, 64,7)\n",
        "\t\t\t\t)\n",
        "\t\t\telse:\n",
        "\t\t\t\tself.conv_list.append(\n",
        "\t\t\t\t\tConvBlock(pool)\n",
        "\t\t\t\t)\n",
        "\t\t# print(len(self.conv_list))\n",
        "\n",
        "\t\tconv_out = 64*int(64/(4*4*2))\n",
        "\t\tself.rnn = nn.GRU(conv_out, 128, num_layers=2, bidirectional=True, batch_first=True, dropout=0.01)\n",
        "\t\tself.rnn_act = nn.Tanh()\n",
        "\n",
        "\t\tself.linear = nn.Linear(128,3*config[\"track\"] *config[\"classes\"])\n",
        "\t\tself.linear1 = nn.Linear(128,128)\n",
        "\t\tself.act1 = nn.Tanh()\n",
        "\t\tself.act = nn.Tanh()\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t# print(\"Forward\")\n",
        "\t\t# print(len(self.conv_list))\n",
        "\t\tfor i in range(len(self.conv_list)):\n",
        "\t\t\tx = self.conv_list[i](x)\n",
        "\t\t# print(\" Post conv list\")\n",
        "\t\n",
        "\t\tx = x.transpose(1, 2).contiguous()\n",
        "\t\tx = x.view(x.shape[0], x.shape[1], -1).contiguous()\n",
        "\t\tx,_ = self.rnn(x)\n",
        "\t\tx = self.rnn_act(x)\n",
        "\t\n",
        "\t\tx = x[:, :, x.shape[-1]//2:] * x[:, :, :x.shape[-1]//2]\n",
        "\n",
        "\t\tx = self.linear1(x)\n",
        "\t\tx = self.act1(x)\n",
        "\t\n",
        "\t\tx = self.linear(x)\n",
        "\t\tx = self.act(x)\n",
        "\t\t\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2pXoNbGawI-3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data.features))\n",
        "print(len(train_data.multi_accdoa))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AePK8SJWXmc9",
        "outputId": "442dd2a4-1337-4e4e-dc55-4d6d06375f03"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189\n",
            "189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional\n",
        "# Test code for checking shapes and return arguments of the train and val loaders\n",
        "for data in train_loader:\n",
        "    x, y = data # if you face an error saying \"Cannot unpack\", then you are not passing the collate_fn argument\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYAkTo8K7C3b",
        "outputId": "791350a7-7df2-4f09-f21c-47d9d4400899"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 7, 250, 64]) torch.Size([128, 3, 3, 12, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4TK4TYP8kjY",
        "outputId": "e28a5745-4ac4-4248-e099-a3f5db43c5b3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummaryX # We also install a summary package to check our model's forward before training\n",
        "from torchsummaryX import summary\n",
        "model = Network_Seldnet().to(device)\n",
        "print(model)\n",
        "summary(model, x.to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snElDB1s8-qj",
        "outputId": "3a099bf8-d131-4f69-8b79-a3ce6edacb89"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsummaryX\n",
            "  Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.21.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.10.0+cu111)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchsummaryX) (3.10.0.2)\n",
            "Installing collected packages: torchsummaryX\n",
            "Successfully installed torchsummaryX-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network_Seldnet().to(device)"
      ],
      "metadata": {
        "id": "nboll0M99wme"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import mse_loss\n",
        "\n",
        "import numpy as np\n",
        "from itertools import permutations\n",
        "\n",
        "\n",
        "class PITLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Loss Function Between Two Multi-ACCDOA Vectors\n",
        "\n",
        "    See also: https://arxiv.org/pdf/2110.07124.pdf\n",
        "    See also: https://github.com/sharathadavanne/seld-dcase2022\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n=3, returnLossArr = False):\n",
        "        \"\"\"\n",
        "        Init Function for PITLoss\n",
        "        :param n: Maximum Number of Simultaneous Sounds from the Same Class\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.returnLossArr = returnLossArr\n",
        "\n",
        "        # Calculate All Permutations of n Unique Elements and Store it In a Numpy Array\n",
        "        index_range = np.arange(n)\n",
        "        self.possible_permutations = np.array(list(set(permutations(index_range))))\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\n",
        "        Loss-Calculating Function for PITLoss\n",
        "        :param x: Estimated Multi-ACCDOA\n",
        "        :param y: True Multi-ACCDOA\n",
        "        :return: PIT Loss\n",
        "        \"\"\"\n",
        "\n",
        "        # Index Through All Possible Permutations of N (Creates A New Axis for Each Permutation)\n",
        "        accdoa_perms = x[:, self.possible_permutations, :, :]\n",
        "\n",
        "        # Expand the True Vector in the Same Way so the Sizes are the Same\n",
        "        new_size = [-1 if i != 1 else len(self.possible_permutations) for i in range(y.dim()+1)]\n",
        "        expanded_labels = torch.unsqueeze(y, 1).expand(*new_size)\n",
        "\n",
        "        # Calculate the Best MSE Loss for Each ACCDOA Permutation\n",
        "        mse_perms = mse_loss(accdoa_perms, expanded_labels, reduction='none')  # Element-Wise Loss\n",
        "        mse_perms_average = torch.mean(mse_perms, dim=[2, 3])  # Average Loss Over N and 3D Dimension\n",
        "        best_mse_perms = torch.min(mse_perms_average, dim=1)  # Find the Min Loss Among Permutations\n",
        "\n",
        "        # Average Min Loss over Classes TODO: Should Time Dimension Be Here?\n",
        "        pit_loss = torch.mean(best_mse_perms.values, [-1-i for i in range(len(best_mse_perms.values.shape)-1)])\n",
        "        # print(pit_loss.size() , \"  hjahkjsdhfjk\")\n",
        "        if self.returnLossArr:\n",
        "          return pit_loss\n",
        "          \n",
        "        pit_loss_term = torch.mean(pit_loss)  # Average over Batch (Should this be sum?)\n",
        "        return pit_loss_term\n"
      ],
      "metadata": {
        "id": "PG2hc2ZtoSIN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "epochs = 80\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * epochs))\n",
        "criterion = PITLoss(returnLossArr=False)"
      ],
      "metadata": {
        "id": "7S7P5M3UoSFU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_save =1 \n"
      ],
      "metadata": {
        "id": "BftOLe78oSB-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# wandb.init(\n",
        "#       # Set the project where this run will be logged\n",
        "#       project=\"dl+hw3_p2_asr\", \n",
        "#       # Track hyperparameters and run metadata\n",
        "#       # config=config\n",
        "# )\n",
        "\n",
        "from datetime import date\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "for epoch in range(epoch_save,epochs+1):\n",
        "    # Quality of life tip: leave=False and position=0 are needed to make tqdm usable in jupyter\n",
        "  batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "  total_loss = 0\n",
        "\n",
        "  for i, (x, y) in enumerate(train_loader):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = x.to(torch.float).cuda()\n",
        "    y = y.to(torch.float).cuda()\n",
        "\n",
        "    with torch.cuda.amp.autocast(): \n",
        "      y_hat = model(x)\n",
        "      y_hat = torch.reshape(y_hat, ((128,3, 3, 13, -1)))\n",
        "      # print(y_hat.size())\n",
        "      # print(y.size())\n",
        "      loss = criterion(y_hat, y).to(torch.float)\n",
        "      # loss = loss.\n",
        "      # print(\"loss \", loss)\n",
        "      # print(type(loss), \"   \", loss.dtype)\n",
        "      \n",
        "      # print(loss.size())\n",
        "\n",
        "    total_loss += float(loss)\n",
        "\n",
        "\n",
        "      # tqdm lets you add some details so you can monitor training as you train.\n",
        "    batch_bar.set_postfix(\n",
        "        loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "        epoch = epoch,\n",
        "        lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "      \n",
        "      # Another couple things you need for FP16. \n",
        "    scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "    scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "    scaler.update() # This is something added just for FP16\n",
        "    scheduler.step()\n",
        "\n",
        "    # scheduler.step() # We told scheduler T_max that we'd call step() (len(train_loader) * epochs) many times.\n",
        "\n",
        "    batch_bar.update() # Update tqdm bar\n",
        "  batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    # You can add validation per-epoch here if you would like\n",
        "\n",
        "  print(\"Epoch {}/{}: Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
        "        epoch,\n",
        "        epochs,\n",
        "        float(total_loss / len(train_loader)),\n",
        "        float(optimizer.param_groups[0]['lr'])))\n",
        "  \n",
        "  # wandb.log({\"Learning Rate\":  float(optimizer.param_groups[0]['lr']) ,\n",
        "  #                       \"Epoch\": epoch, \"Loss\":float(total_loss / len(train_loader)),})\n",
        "  \n",
        "  \n",
        "\n",
        "#   MODEL_NAME = \"medium_arch\" + str(date.today().strftime(\"%d_%m_%Y\")) + \"_\"+str(epoch) + \".pt\"\n",
        "#   torch.save({\n",
        "#         #   'epoch': 10,\n",
        "#           'model_state_dict': model.state_dict(),\n",
        "#           'optimizer_state_dict': optimizer.state_dict(),\n",
        "#           'schedule_state_dict': scheduler.state_dict(),\n",
        "#           'epoch_save': epoch,\n",
        "#         #   'loss': 0.001,\n",
        "#   }, os.path.join(wandb.run.dir, MODEL_NAME))\n",
        "\n",
        "#   wandb.save(MODEL_NAME)\n",
        "\n",
        "#   if epoch%10 == 0:\n",
        "#     lev_dist = validate(model)\n",
        "#     print(\"Lev distance is \", lev_dist)\n",
        "#     wandb.log({\"Learning Rate\":  float(optimizer.param_groups[0]['lr']) ,\n",
        "#                         \"Epoch\": epoch, \"Loss\":float(total_loss / len(train_loader)), \"Lev Distance\" : lev_dist})\n",
        "\n",
        "\n",
        "# wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aVJQy9doR-i",
        "outputId": "ffa122cb-39d4-4e7f-d45b-616af7b9efee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80: Train Loss 0.0459, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/80: Train Loss 0.0449, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/80: Train Loss 0.0434, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/80: Train Loss 0.0438, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/80: Train Loss 0.0439, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/80: Train Loss 0.0437, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/80: Train Loss 0.0431, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/80: Train Loss 0.0427, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/80: Train Loss 0.0435, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/80: Train Loss 0.0429, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/80: Train Loss 0.0428, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/80: Train Loss 0.0426, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/80: Train Loss 0.0428, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/80: Train Loss 0.0430, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/80: Train Loss 0.0430, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/80: Train Loss 0.0426, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/80: Train Loss 0.0428, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/80: Train Loss 0.0425, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/80: Train Loss 0.0427, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/80: Train Loss 0.0424, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/80: Train Loss 0.0429, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/80: Train Loss 0.0426, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/80: Train Loss 0.0428, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/80: Train Loss 0.0422, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/80: Train Loss 0.0424, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/80: Train Loss 0.0425, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/80: Train Loss 0.0426, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/80: Train Loss 0.0425, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/80: Train Loss 0.0423, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/80: Train Loss 0.0419, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/80: Train Loss 0.0424, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/80: Train Loss 0.0422, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/80: Train Loss 0.0424, Learning Rate 0.0006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/80: Train Loss 0.0421, Learning Rate 0.0006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/80: Train Loss 0.0419, Learning Rate 0.0006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/80: Train Loss 0.0420, Learning Rate 0.0006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/80: Train Loss 0.0419, Learning Rate 0.0006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/80: Train Loss 0.0412, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/80: Train Loss 0.0415, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/80: Train Loss 0.0414, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/80: Train Loss 0.0413, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/80: Train Loss 0.0413, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/80: Train Loss 0.0407, Learning Rate 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/80: Train Loss 0.0412, Learning Rate 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/80: Train Loss 0.0411, Learning Rate 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/80: Train Loss 0.0412, Learning Rate 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/80: Train Loss 0.0410, Learning Rate 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/80: Train Loss 0.0409, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/80: Train Loss 0.0413, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/80: Train Loss 0.0405, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/80: Train Loss 0.0411, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/80: Train Loss 0.0407, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/80: Train Loss 0.0410, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/80: Train Loss 0.0405, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/80: Train Loss 0.0403, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/80: Train Loss 0.0403, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/80: Train Loss 0.0402, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/80: Train Loss 0.0404, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/80: Train Loss 0.0404, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/80: Train Loss 0.0405, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/80: Train Loss 0.0400, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62/80: Train Loss 0.0398, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63/80: Train Loss 0.0398, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64/80: Train Loss 0.0405, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65/80: Train Loss 0.0401, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/80: Train Loss 0.0398, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67/80: Train Loss 0.0400, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68/80: Train Loss 0.0401, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69/80: Train Loss 0.0401, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/80: Train Loss 0.0398, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71/80: Train Loss 0.0397, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72/80: Train Loss 0.0398, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73/80: Train Loss 0.0396, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74/80: Train Loss 0.0397, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75/80: Train Loss 0.0397, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76/80: Train Loss 0.0392, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77/80: Train Loss 0.0399, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78/80: Train Loss 0.0397, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7fG0ipgtoR51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RV6DT2iRoR1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qVZhRaznoRQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sharathadavanne/seld-dcase2022.git"
      ],
      "metadata": {
        "id": "9546YJC49mKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6eb1f5-8122-4039-e98a-3cacca2ef723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'seld-dcase2022'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 103 (delta 66), reused 65 (delta 31), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (103/103), 1.06 MiB | 7.88 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys  \n",
        "sys.path.insert(0, '/content/seld-dcase2022')"
      ],
      "metadata": {
        "id": "7VbLkjzTbpJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/seld-dcase2022/batch_feature_extraction.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MytxeoQQbBuH",
        "outputId": "a27c1239-0bf4-4887-caf9-dc236d667bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16: fold4_room24_mix003.wav, (4865, 448)\n",
            "17: fold4_room24_mix005.wav, (6865, 448)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/seld-dcase2022/batch_feature_extraction.py\", line 30, in <module>\n",
            "    sys.exit(main(sys.argv))\n",
            "  File \"/content/seld-dcase2022/batch_feature_extraction.py\", line 22, in main\n",
            "    dev_feat_cls.extract_all_feature()\n",
            "  File \"/content/seld-dcase2022/cls_feature_class.py\", line 380, in extract_all_feature\n",
            "    self.extract_file_feature((file_cnt, wav_path, feat_path))\n",
            "  File \"/content/seld-dcase2022/cls_feature_class.py\", line 338, in extract_file_feature\n",
            "    mel_spect = self._get_mel_spectrogram(spect)\n",
            "  File \"/content/seld-dcase2022/cls_feature_class.py\", line 135, in _get_mel_spectrogram\n",
            "    log_mel_spectra = librosa.power_to_db(mel_spectra)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py\", line 1559, in power_to_db\n",
            "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat = np.load('/content/gdrive/MyDrive/ProjectData/data/seld_feat_label/foa_dev/fold4_room23_mix002.npy')"
      ],
      "metadata": {
        "id": "ouSmiK1jbjc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12LWsIX4cV0Z",
        "outputId": "5665bef6-141e-4a96-c215-fcd76b4eba3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3035, 448)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQwhELkOcWre",
        "outputId": "73c6ade8-8be4-40e5-893a-670851e21352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2235, 448)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/seld-dcase2022/train_seldnet.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUJqQy7ica3V",
        "outputId": "3a0dbca6-58b1-4928-b002-134ed71f6826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/seld-dcase2022/train_seldnet.py']\n",
            "\n",
            "\n",
            "\n",
            "-------------------------------------------------------------------------------------------------------\n",
            "The code expected two optional inputs\n",
            "\t>> python seld.py <task-id> <job-id>\n",
            "\t\t<task-id> is used to choose the user-defined parameter set from parameter.py\n",
            "Using default inputs for now\n",
            "\t\t<job-id> is a unique identifier which is used for output filenames (models, training plots). You can use any number or string for this.\n",
            "-------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "SET: 1\n",
            "USING DEFAULT PARAMETERS\n",
            "\n",
            "\tquick_test: True\n",
            "\tfinetune_mode: False\n",
            "\tpretrained_model_weights: models/1_1_foa_dev_split6_model.h5\n",
            "\tdataset_dir: /content/gdrive/MyDrive/ProjectData/data\n",
            "\tunique_classes: 13\n",
            "\tfeat_label_dir: /content/gdrive/MyDrive/ProjectData/data/seld_feat_label\n",
            "\tmodel_dir: models/\n",
            "\tdcase_output_dir: results/\n",
            "\tmode: dev\n",
            "\tdataset: foa\n",
            "\tfs: 24000\n",
            "\thop_len_s: 0.02\n",
            "\tlabel_hop_len_s: 0.1\n",
            "\tmax_audio_len_s: 60\n",
            "\tnb_mel_bins: 64\n",
            "\tuse_salsalite: False\n",
            "\tfmin_doa_salsalite: 50\n",
            "\tfmax_doa_salsalite: 2000\n",
            "\tfmax_spectra_salsalite: 9000\n",
            "\tmulti_accdoa: True\n",
            "\tthresh_unify: 15\n",
            "\tlabel_sequence_length: 50\n",
            "\tbatch_size: 128\n",
            "\tdropout_rate: 0.05\n",
            "\tnb_cnn2d_filt: 64\n",
            "\tf_pool_size: [4, 4, 2]\n",
            "\tnb_rnn_layers: 2\n",
            "\trnn_size: 128\n",
            "\tself_attn: False\n",
            "\tnb_heads: 4\n",
            "\tnb_fnn_layers: 1\n",
            "\tfnn_size: 128\n",
            "\tnb_epochs: 100\n",
            "\tlr: 0.001\n",
            "\taverage: macro\n",
            "\tlad_doa_thresh: 20\n",
            "\tfeature_sequence_length: 250\n",
            "\tt_pool_size: [5, 1, 1]\n",
            "\tpatience: 100\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "------------------------------------      SPLIT [4]   -----------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------\n",
            "unique_name: 1_1_dev_split0_multiaccdoa_foa\n",
            "\n",
            "---------------- SELD-net -------------------\n",
            "FEATURES:\n",
            "\tdata_in: (128, 7, 250, 64)\n",
            "\tdata_out: (128, 250, 117)\n",
            "\n",
            "MODEL:\n",
            "\tdropout_rate: 0.05\n",
            "\tCNN: nb_cnn_filt: 64, f_pool_size[4, 4, 2], t_pool_size[5, 1, 1]\n",
            "\trnn_size: 128, fnn_size: 128\n",
            "\n",
            "CRNN(\n",
            "  (conv_block_list): ModuleList(\n",
            "    (0): ConvBlock(\n",
            "      (conv): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): MaxPool2d(kernel_size=(5, 4), stride=(5, 4), padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): Dropout2d(p=0.05, inplace=False)\n",
            "    (3): ConvBlock(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Dropout2d(p=0.05, inplace=False)\n",
            "    (6): ConvBlock(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (7): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Dropout2d(p=0.05, inplace=False)\n",
            "  )\n",
            "  (gru): GRU(128, 128, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
            "  (fnn_list): ModuleList(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (1): Linear(in_features=128, out_features=117, bias=True)\n",
            "  )\n",
            ")\n",
            "Dumping recording-wise val results in: results/1_1_dev_split0_multiaccdoa_foa_20220402103551_val\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/seld-dcase2022/train_seldnet.py\", line 387, in <module>\n",
            "    sys.exit(main(sys.argv))\n",
            "  File \"/content/seld-dcase2022/train_seldnet.py\", line 296, in main\n",
            "    score_obj = ComputeSELDResults(params)\n",
            "  File \"/content/seld-dcase2022/cls_compute_seld_results.py\", line 24, in __init__\n",
            "    gt_dict = self._feat_cls.load_output_format_file(os.path.join(self._desc_dir, split, ref_file))\n",
            "  File \"/content/seld-dcase2022/cls_feature_class.py\", line 468, in load_output_format_file\n",
            "    _words = _line.strip().split(',')\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EAD43Z3jhNsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WZM2vIH6hqJO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}