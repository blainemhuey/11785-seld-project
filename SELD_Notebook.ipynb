{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f61697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c776979",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SOUND_EVENT_CLASSES = [\n",
    "    \"Female speech, woman speaking\",\n",
    "    \"Male speech, man speaking\",\n",
    "    \"Clapping\",\n",
    "    \"Telephone\",\n",
    "    \"Laughter\",\n",
    "    \"Domestic sounds\",\n",
    "    \"Walk, footsteps\",\n",
    "    \"Door, open or close\",\n",
    "    \"Music\",\n",
    "    \"Musical instrument\",\n",
    "    \"Water tap, faucet\",\n",
    "    \"Bell\",\n",
    "    \"Knock\"\n",
    "]\n",
    "\n",
    "\n",
    "class FOADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for DCASE FOA Datsets\n",
    "\n",
    "    TODO: CURRENTLY IMPLEMENTS MEL SPECTRA AND INTENSITY VECTORS (i.e. SELDNet Inputs)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path, folds=None, train=True):\n",
    "        \"\"\"\n",
    "        Init Function for FOADataset\n",
    "        :param data_path: String path to root folder containing 'foa_dev' and 'metadata_dev'\n",
    "        :param folds: List of fold integers to use in this dataset\n",
    "        :param train: Bool indicating whether to use train dataset of val dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate Directory Names\n",
    "        foa_directory_sony = osp.join(data_path, \"foa_dev\", \"dev-train-sony\" if train else \"dev-test-sony\")\n",
    "        meta_directory_sony = osp.join(data_path, \"metadata_dev\", \"dev-train-sony\" if train else \"dev-test-sony\")\n",
    "        foa_directory_tau = osp.join(data_path, \"foa_dev\", \"dev-train-tau\" if train else \"dev-test-tau\")\n",
    "        meta_directory_tau = osp.join(data_path, \"metadata_dev\", \"dev-train-tau\" if train else \"dev-test-tau\")\n",
    "\n",
    "        all_foa_files = [osp.join(foa_directory_tau, file) for file in os.listdir(foa_directory_tau)]\n",
    "        all_foa_files.extend([osp.join(foa_directory_sony, file) for file in os.listdir(foa_directory_sony)])\n",
    "        all_meta_files = [osp.join(meta_directory_tau, file) for file in os.listdir(meta_directory_tau)]\n",
    "        all_meta_files.extend([osp.join(meta_directory_sony, file) for file in os.listdir(meta_directory_sony)])\n",
    "\n",
    "        # Parse File Names\n",
    "        foa_file_data = [self.parse_foa_file_name(file) for file in all_foa_files]\n",
    "        meta_file_data = [self.parse_foa_file_name(file) for file in all_meta_files]\n",
    "\n",
    "        # Create Lists of All Valid File Paths in Given Folds\n",
    "        self.folds = folds\n",
    "        self.foa_files = [\n",
    "            file for file, data in zip(all_foa_files, foa_file_data)\n",
    "            if (folds is None or data[\"fold\"] in folds)\n",
    "        ]\n",
    "        self.foa_files.sort()\n",
    "        self.meta_files = [\n",
    "            file for file, data in zip(all_meta_files, meta_file_data)\n",
    "            if (folds is None or data[\"fold\"] in folds)\n",
    "        ]\n",
    "        self.meta_files.sort()\n",
    "        assert len(self.foa_files) == len(self.meta_files)\n",
    "\n",
    "        # TODO: Add Options for Other Input Features\n",
    "        # Load SELDNet Input Features and ACCDOA Output\n",
    "        features = []\n",
    "        multi_accdoas = []\n",
    "        for foa_file, meta_file in zip(self.foa_files, self.meta_files):\n",
    "            feature = self.audio_to_foa_features(foa_file)\n",
    "            multi_accdoa = self.metadata_to_multi_accdoa(self.load_metadata(meta_file),\n",
    "                                                         total_frames=feature.shape[2])\n",
    "            features.append(feature)\n",
    "            multi_accdoas.append(multi_accdoa)\n",
    "        self.features = torch.concat(features, dim=-1)\n",
    "        self.multi_accdoa = np.concatenate(multi_accdoas, axis=-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_foa_file_name(file):\n",
    "        \"\"\"\n",
    "        Parses filenames of the following format:\n",
    "        \"fold[fold number]_room[room number per fold]_mix[recording number per room per split].wav\"\n",
    "        :param file: filename\n",
    "        :return: metadata dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        name, extension = osp.splitext(osp.basename(file))\n",
    "        fold_text, room_text, mix_text = name.split(\"_\")\n",
    "        fold = int(fold_text.replace(\"fold\", \"\"))\n",
    "        room = int(room_text.replace(\"room\", \"\"))\n",
    "        mix = int(mix_text.replace(\"mix\", \"\"))\n",
    "        return {\"fold\": fold, \"room\": room, \"mix\": mix}\n",
    "\n",
    "    @staticmethod\n",
    "    def audio_to_foa_features(file, fft_size=1024, hop_length=20):\n",
    "        \"\"\"\n",
    "        Generates the SELDNet Input Features\n",
    "        :param file: Filepath to Audio File to Load\n",
    "        :param fft_size: Size of FFT calculation to perform\n",
    "        :param hop_length: Stride of FFT in ms\n",
    "        :return: torch.Tensor of Shape 7x64xT\n",
    "        \"\"\"\n",
    "        waveform, sample_rate = torchaudio.load(file)\n",
    "#                                                 normalize=True)\n",
    "\n",
    "        spec_trans = torchaudio.transforms.Spectrogram(n_fft=fft_size, hop_length=sample_rate // (1000 // hop_length),\n",
    "                                                       pad=0, power=None)\n",
    "        mel_trans = torchaudio.transforms.MelScale(n_mels=64, sample_rate=sample_rate, n_stft=fft_size // 2 + 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            spectrogram = spec_trans(waveform)\n",
    "            mel_spec = mel_trans(torch.real(torch.pow(spectrogram, 2)))\n",
    "\n",
    "            intensity = torch.real(torch.conj(spectrogram[0]) * spectrogram[1:])\n",
    "            intensity = intensity / torch.norm(intensity, dim=0)  # TODO: Check shape\n",
    "            mel_intensity = mel_trans(intensity)\n",
    "        return torch.concat((mel_spec, mel_intensity), dim=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_metadata(file):\n",
    "        \"\"\"\n",
    "        Reads in the CSV Label File of the Format\n",
    "        '[frame number (int)], [active class index (int)], [source number index (int)], [azimuth (int)], [elevation (int)]'\n",
    "\n",
    "        :param file: Filepath to CSV File to Load\n",
    "        :return: List of Metadata Dictionaries\n",
    "        \"\"\"\n",
    "        metadata = []\n",
    "        with open(file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                frame_number, active_class, source_number, azimuth, elevation = line.split(\",\")\n",
    "                metadata.append({\n",
    "                    \"frame_number\": int(frame_number),\n",
    "                    \"active_class\": int(active_class),\n",
    "                    \"source_number\": int(source_number),\n",
    "                    \"azimuth\": int(azimuth),\n",
    "                    \"elevation\": int(elevation)\n",
    "                })\n",
    "        return metadata\n",
    "\n",
    "    @staticmethod\n",
    "    def metadata_to_multi_accdoa(metadata, total_frames, n=2, c=len(SOUND_EVENT_CLASSES)):\n",
    "        multi_accdoa = np.zeros((n, 3, c, total_frames))\n",
    "        event_count_per_frame = np.zeros((c, total_frames), dtype=np.int)\n",
    "        for metadata_i in metadata:\n",
    "            f, a, s, az, el = (metadata_i[\"frame_number\"], metadata_i[\"active_class\"], metadata_i[\"source_number\"],\n",
    "                               metadata_i[\"azimuth\"], metadata_i[\"elevation\"])\n",
    "            norm_az_el = np.array([np.cos(np.deg2rad(az)), np.sin(np.deg2rad(az)), np.sin(np.deg2rad(el))])\n",
    "            multi_accdoa[:, event_count_per_frame[a, f]:, a, f] = norm_az_el\n",
    "#             print(norm_az_el.shape, \"   norm az el\")\n",
    "            event_count_per_frame[a, f] += 1\n",
    "            if event_count_per_frame[a, f] >=1 :\n",
    "                print(multi_accdoa[:,:,a,f], \"   multttii\")\n",
    "        return multi_accdoa\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[-1]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.features[:, :, item], self.multi_accdoa[:, :, :, item]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc6dc63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YashKarnawat\\AppData\\Local\\Temp\\ipykernel_22548\\2794665735.py:141: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  event_count_per_frame = np.zeros((c, total_frames), dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[-0.1391731  -0.99026807 -0.27563736]\n",
      " [-0.1391731  -0.99026807 -0.27563736]]    multttii\n",
      "[[ 0.61566148 -0.78801075 -0.61566148]\n",
      " [ 0.61566148 -0.78801075 -0.61566148]]    multttii\n",
      "[[ 0.61566148 -0.78801075 -0.61566148]\n",
      " [ 0.61566148 -0.78801075 -0.61566148]]    multttii\n",
      "[[ 0.61566148 -0.78801075 -0.61566148]\n",
      " [ 0.61566148 -0.78801075 -0.61566148]]    multttii\n",
      "[[ 0.62932039 -0.77714596 -0.61566148]\n",
      " [ 0.62932039 -0.77714596 -0.61566148]]    multttii\n",
      "[[ 0.62932039 -0.77714596 -0.61566148]\n",
      " [ 0.62932039 -0.77714596 -0.61566148]]    multttii\n",
      "[[ 0.62932039 -0.77714596 -0.62932039]\n",
      " [ 0.62932039 -0.77714596 -0.62932039]]    multttii\n",
      "[[ 0.62932039 -0.77714596 -0.62932039]\n",
      " [ 0.62932039 -0.77714596 -0.62932039]]    multttii\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,) into shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mFOADataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE:/11785/project/data_2022/foa_dev\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader( train_data , batch_size\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_data))\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mFOADataset.__init__\u001b[1;34m(self, data_path, folds, train)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m foa_file, meta_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfoa_files, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_files):\n\u001b[0;32m     67\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_to_foa_features(foa_file)\n\u001b[1;32m---> 68\u001b[0m     multi_accdoa \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata_to_multi_accdoa\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mtotal_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(feature)\n\u001b[0;32m     71\u001b[0m     multi_accdoas\u001b[38;5;241m.\u001b[39mappend(multi_accdoa)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mFOADataset.metadata_to_multi_accdoa\u001b[1;34m(metadata, total_frames, n, c)\u001b[0m\n\u001b[0;32m    143\u001b[0m             f, a, s, az, el \u001b[38;5;241m=\u001b[39m (metadata_i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe_number\u001b[39m\u001b[38;5;124m\"\u001b[39m], metadata_i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_class\u001b[39m\u001b[38;5;124m\"\u001b[39m], metadata_i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_number\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    144\u001b[0m                                metadata_i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazimuth\u001b[39m\u001b[38;5;124m\"\u001b[39m], metadata_i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melevation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    145\u001b[0m             norm_az_el \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mcos(np\u001b[38;5;241m.\u001b[39mdeg2rad(az)), np\u001b[38;5;241m.\u001b[39msin(np\u001b[38;5;241m.\u001b[39mdeg2rad(az)), np\u001b[38;5;241m.\u001b[39msin(np\u001b[38;5;241m.\u001b[39mdeg2rad(el))])\n\u001b[1;32m--> 146\u001b[0m             multi_accdoa[:, event_count_per_frame[a, f]:, a, f] \u001b[38;5;241m=\u001b[39m norm_az_el\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m#             print(norm_az_el.shape, \"   norm az el\")\u001b[39;00m\n\u001b[0;32m    148\u001b[0m             event_count_per_frame[a, f] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3,) into shape (2,2)"
     ]
    }
   ],
   "source": [
    "train_data = FOADataset(\"E:/11785/project/data_2022/foa_dev\")\n",
    "train_loader = torch.utils.data.DataLoader( train_data , batch_size= 2, shuffle=True)\n",
    "\n",
    "\n",
    "print(len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2170eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PySoundFile"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading PySoundFile-0.9.0.post1-py2.py3.cp26.cp27.cp32.cp33.cp34.cp35.cp36.pp27.pp32.pp33-none-win_amd64.whl (671 kB)\n",
      "Requirement already satisfied: cffi>=0.6 in e:\\anaconda3\\lib\\site-packages (from PySoundFile) (1.15.0)\n",
      "Requirement already satisfied: pycparser in e:\\anaconda3\\lib\\site-packages (from cffi>=0.6->PySoundFile) (2.21)\n",
      "Installing collected packages: PySoundFile\n",
      "Successfully installed PySoundFile-0.9.0.post1\n"
     ]
    }
   ],
   "source": [
    "# !pip install PySoundFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be49f65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
